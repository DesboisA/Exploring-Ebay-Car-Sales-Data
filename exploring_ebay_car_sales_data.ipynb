{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "It this project, the following dataset of [used cars from eBay Kleinanzeigen](https://data.world/data-society/used-cars-data), a classifieds section of the German eBay website, will be used.\n",
    "\n",
    "### Table of Contents <a class=\"anchor\" id=\"s0\"></a>\n",
    "\n",
    "* [Dataset and aim of the study](#s1)\n",
    "* [Data cleaning and exploration](#s2)\n",
    "* [Odometer investigation](#s3)\n",
    "* [Registration year investigation](#s4)\n",
    "* [Exploring Price by Brand](#s5)\n",
    "* [Correlation between price and mileage (odometer_km)?](#s6)\n",
    "* [Further data cleaning](#s7)\n",
    "* [Most common brand/model combinations](#s8)\n",
    "* [How much cheaper are cars with damage than their non-damaged counterparts?](#s9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and aim of the study <a class=\"anchor\" id=\"s1\"></a>\n",
    "\n",
    "<span style='background :yellow' > Few modifications were made from the original dataset:</span>\n",
    "- Sampled down to 50,000 data points to ensure the code runs quickly\n",
    "- Modified to bring it closer to a real scraped dataset\n",
    "\n",
    "---\n",
    "--- \n",
    "\n",
    "The data dictionary provided with the dataset is as follows:\n",
    "\n",
    "| Column name | Description |\n",
    "| :--- | :--- |\n",
    "|dateCrawled| When this ad was first crawled. All field-values are taken from this date.|\n",
    "|seller| Whether the seller is private or a dealer.|\n",
    "|offerType | The type of listing.| \n",
    "|price| The price on the ad to sell the car.|\n",
    "|abtest| Whether the listing is included in an A/B test.|\n",
    "|vehicleType| The vehicle Type.|\n",
    "|yearOfRegistration| The year in which the car was first registered.|\n",
    "|gearbox| The transmission type.|\n",
    "|powerPS| The power of the car in PS.|\n",
    "|model| The car model name.|\n",
    "|kilometer| How many kilometers the car has driven.|\n",
    "|monthOfRegistration| The month in which the car was first registered.|\n",
    "|fuelType| What type of fuel the car uses.|\n",
    "|brand| The brand of the car.|\n",
    "|notRepairedDamage| If the car has a damage which is not yet repaired.|\n",
    "|dateCreated| The date on which the eBay listing was created.|\n",
    "|nrOfPictures| The number of pictures in the ad.|\n",
    "|postalCode| The postal code for the location of the vehicle.|\n",
    "|lastSeenOnline| When the crawler saw this ad last online.|\n",
    "\n",
    "---\n",
    "\n",
    "### <span style='color:Blue'> The aim of this project is to clean the data and analyze the included used car listings.<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'autos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7cb761e3fb1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mautos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'autos.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Latin-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\desboisa\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'autos.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "autos = pd.read_csv('autos.csv', encoding = 'Latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a lot of data columns are object data type despit it should be integer or float, such as:\n",
    "- dateCrawled\n",
    "- price                \n",
    "- odometer             \n",
    "- dateCreated          \n",
    "- lastSeen             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and exploration <a class=\"anchor\" id=\"s2\"></a>\n",
    "\n",
    "The value of rangeindex provided for the index axis indicates **371528** entries.\n",
    "\n",
    "The summary includes list of all columns with their data types, most of which are strings, and the number of non-null values in each column. \n",
    "\n",
    "The following columns have null values, all with string values:\n",
    "- vehicleType \n",
    "- gearbox\n",
    "- model\n",
    "- fuelType\n",
    "- notRepairedDamage\n",
    "\n",
    "Note that column names use camelcase instead of Python's preferred snakecase. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['date_crawled', 'name', 'seller', 'offer_type', 'price', 'abtest',\n",
    "       'vehicle_type', 'registration_year', 'gearbox', 'powerPS', 'model',\n",
    "       'odometer', 'registration_month', 'fuel_type', 'brand',\n",
    "       'unrepaired_damage', 'ad_created', 'nr_of_pictures', 'postal_code',\n",
    "       'last_seen']\n",
    "\n",
    "autos.columns = new_columns\n",
    "\n",
    "print(autos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names were converted from camelcase to snakecase and some of the column names were reworded based on the data dictionary to be more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.gearbox.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data, we can see that <span style='background:pink'>price</span> and <span style='background:pink'>odometer</span> columns are numeric values stored as text. \n",
    "\n",
    "For each column:\n",
    "- Any non-numeric character will be removed;\n",
    "- The column will be converted to a numeric dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[\"price\"] = autos[\"price\"].str.replace('$','')\n",
    "autos[\"price\"] = autos[\"price\"].str.replace(',','')\n",
    "autos[\"price\"] = autos[\"price\"].astype(int)\n",
    "autos[\"price\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[\"odometer\"] = autos[\"odometer\"].str.replace('km','')\n",
    "autos[\"odometer\"] = autos[\"odometer\"].str.replace(',','')\n",
    "autos[\"odometer\"] = autos[\"odometer\"].astype(int)\n",
    "autos.rename({\"odometer\": \"odometer_km\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[\"odometer_km\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check these column to look for any values that look unrealistically high or low (outliers) that might be good to remove.\n",
    "\n",
    "## Odometer investigation <a class=\"anchor\" id=\"s3\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique values?\n",
    "autos[\"odometer_km\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "autos[\"odometer_km\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count in ascending order\n",
    "autos[\"odometer_km\"].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[(autos[\"odometer_km\"]==150000)].sort_index(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the price and brand car, the data for the **odometer_km** column are coherent and are not outliers. A quick look at this [website](https://www.autoscout24.com/lst/opel/vectra) confirms this hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price investigation <a class=\"anchor\" id=\"s4\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique values?\n",
    "autos[\"price\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "autos[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count in descending order\n",
    "autos[\"price\"].value_counts().sort_index(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the price value count shows us <span style='background :yellow'> **OUTLIERS** with price > 350 000 $ </span>.\n",
    "\n",
    "Let's confirm by looking closely at the most expansive used car of the database if it \"makes sense\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[autos[\"price\"]>=350000].sort_values(by='price', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at this [website](https://www.reezocar.com/en/) shows **Porsh 991** price around 345,000 \\\\$  for 5000 km used. But a **Volkswagen Jetta Gt** from 1989 with 280,000 km used is sold at 2,230 \\\\$ approximately. This confirms OUTLIERS with price > 350,000 \\\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count in ascending order\n",
    "autos[\"price\"].value_counts().sort_index(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos[autos[\"price\"] == 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A price of 0\\\\$ usually indicated a price on demand. A quick look at this [website](https://www.reezocar.com/en/) shows **Porsche Targa 911 S** with a price on demand. If we check used **Porsche 911** for the years arounf 1970 and 5000 km used, prices are superior to 80,000 \\\\$. So we might want to exclude the price on demand, hence the rows with a price == 0\\\\$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos=autos[(autos[\"price\"] >= 1) & (autos[\"price\"] <= 350000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration year investigation <a class=\"anchor\" id=\"s4\"></a>\n",
    "---\n",
    "\n",
    "The <span style='background:pink'>date_crawled</span>, <span style='background:pink'>last_seen</span> and <span style='background:pink'>ad_created</span> columns are all identified as string values. Because these three columns are represented as strings, we need to convert the data into a numerical representation so we can understand it quantitatively. Let's first understand how the values in the three string columns are formatted. These columns all represent full timestamp values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos[['date_crawled','ad_created','last_seen']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna = 'True' will include missing values, and normalize = true will use percentages instead of counts\n",
    "print(\"First added by the crawler: \\n\")\n",
    "df1=clean_autos['date_crawled'].str[:10].value_counts(normalize=True, dropna=False).sort_index()\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nWhen the crawler saw this ad last online: \\n\")\n",
    "df2=clean_autos['last_seen'].str[:10].value_counts(normalize=True, dropna=False).sort_index()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nThe date on which the eBay listing was created.\\n\")\n",
    "df3=clean_autos['ad_created'].str[:10].value_counts(normalize=True, dropna=False).sort_index()\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are inaccuracies between `date_crawled` or `ad_created` for any car with a `registration_year` above 2016. Indeed, a car cannot be first registered after the eBay listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos['registration_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum and maximum values indicate odd values: \n",
    "- `min` = 1000, which is inferior to the [year 1886 is regarded as the birth year of the modern car](https://en.wikipedia.org/wiki/Car#:~:text=The%20year%201886%20is%20regarded,by%20the%20Ford%20Motor%20Company.)\n",
    "- `max` = 9999, which is far superior to the current year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos['registration_year'].value_counts().sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick search on internet indicates cars were invented in the late 1800s. Let's see what kind of cars are listed for the year `1910` and `1927`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos[(clean_autos['registration_year']==1910) | (clean_autos['registration_year']==1927)].sort_values(by='registration_year', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick search on internet indicates Renault Twingo first generation was in 1993. But the [Essex super six Ford]('https://www.conceptcarz.com/vehicle/z11897/essex-super-six.aspx') is a car from the year `1927` which is the lowest acceptable registration year of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos['registration_year'].value_counts().sort_index().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the values outside the 1927 - 2016 interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos=clean_autos[(clean_autos['registration_year'] >=1927) & (clean_autos['registration_year'] <=2016)]\n",
    "clean_autos['registration_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos['registration_year'].value_counts(normalize=True).head(10).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars with a registration year between the `1998-2007` interval are the most listed on eBay. `2000`being the registration year with most listed cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Price by Brand <a class=\"anchor\" id=\"s5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_autos['brand'].value_counts(normalize=True, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore variations across different car brands in terms of __price__. In order to do so, we will aggregate over the top 20 brands using `Series.index` attribute to access the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_brands= clean_autos['brand'].value_counts(normalize=True, sort=True).index[:20]\n",
    "selected_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_mean_price = {}\n",
    "\n",
    "for b in selected_brands:\n",
    "    sel_brand = clean_autos[clean_autos['brand']== b]\n",
    "    brand_mean_price[b] = sel_brand['price'].mean().round()\n",
    "    \n",
    "brand_mean_price_sorted=sorted(brand_mean_price.items(), key=lambda item: item[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .from_records() method to creates a DataFrame object from a structured ndarray\n",
    "pd.DataFrame.from_records(brand_mean_price_sorted, columns=[\"Brand\", \"Price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, __sonstige__ and __mini__ cars are the most expansive cars listed on eBay with an average price superior to 10k\\\\$. __Audi__ cars are not far behind with an average price superior to 9k\\\\$  The least expansive listed cars on eBay are __opel__, __fiat__ and __renault__ cars with an average price under 3k\\\\$. Let's use aggregation to understand the average mileage for those cars and see if there's any visible link with mean price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between price and mileage (odometer_km)? <a class=\"anchor\" id=\"s6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_mean_odometer = {}\n",
    "\n",
    "for b in selected_brands:\n",
    "    sel_brand = clean_autos[clean_autos['brand']== b]\n",
    "    brand_mean_odometer[b] = sel_brand['odometer_km'].mean().round()\n",
    "\n",
    "# Convert both dictionaries to series objects, using the series constructor\n",
    "bmp_series= pd.Series(brand_mean_price)\n",
    "bmo_series= pd.Series(brand_mean_odometer)\n",
    "\n",
    "#Create a dataframe from the first series object using the dataframe constructor\n",
    "df = pd.DataFrame(bmp_series, columns=['mean_price'])\n",
    "df['mean_odometer_km'] = bmo_series\n",
    "df.sort_values('mean_price', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, __sonstige__ and __mini__ cars stand out a little bit with an average mileage lower than the rest of the cars. Unfortunately, it is difficult to judge the impact of mileage among the different car brands as such. Let's create a subset of the dataframe for __Upper middle class cars__. Mileage will be grouped into 3 bins in order to have a wider sens of its influence on the average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_middle_class = clean_autos[(clean_autos['brand']== 'sonstige_autos')|(clean_autos['brand']== 'mini')|(clean_autos['brand']== 'audi')|(clean_autos['brand']== 'mercedes_benz')|(clean_autos['brand']== 'bmw')]\n",
    "print(\"The 3 intervals of mileage for upper middle class cars:\")\n",
    "upper_middle_class['odometer_km'].value_counts(bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mileage group 1 (101666.667, 150000.0]\n",
    "price1=upper_middle_class.loc[upper_middle_class['odometer_km'] >= 101666.667, 'price'].mean().round()\n",
    "print(\"Average price for cars with mileage range from 101666.667 to 150000.0 kms: \", price1, \"$\")\n",
    "\n",
    "# Mileage group2 (53333.333, 101666.667]\n",
    "price2=upper_middle_class.loc[(upper_middle_class['odometer_km'] > 53333.333) & (upper_middle_class['odometer_km'] <101666.667), 'price'].mean().round()\n",
    "print(\"Average price for cars with mileage range from 53333.333 to 101666.667 kms: \", price2, \"$\")\n",
    "\n",
    "# Mileage group 3 (4854.999, 53333.333]\n",
    "price3=upper_middle_class.loc[upper_middle_class['odometer_km'] <= 53333.333, 'price'].mean().round()\n",
    "print(\"Average price for cars with mileage range from 4854.999 to 53333.333 kms: \", price3, \"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some conclusion we can draw from these results:\n",
    "- In general, brand reputation affects more the price listed than recorded mileage\n",
    "- For upper middle class cars, price tends to be less expansive with higher mileage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further data cleaning <a class=\"anchor\" id=\"s7\"></a>\n",
    "\n",
    "As further data cleaning, something we could do is to identify categorical data that uses german words to translate them and map the calues to their english counterparts.\n",
    "\n",
    "As we saw in the [Dataset and aim of the study](#s1), the following columns have the dtypes `object`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = clean_autos.select_dtypes(include='object')\n",
    "categorical_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the columns related with dates or to the properties of the car such as the columns __model__ and __brand__. Let's use the pandas function `.unique` to verify what kind of **unique** value each column returns and if they are in German and translate them in english using Google Translate and finally using the pandas function `.replace` to map the values to their english counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique value for 'seller' column - before replace : \\n\", categorical_data['seller'].unique())\n",
    "clean_autos['seller'].replace({\"gewerblich\":\"commercial\"},inplace = True)\n",
    "print(\"\\nUnique value for 'seller' column - after replace : \\n\", clean_autos['seller'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique value for 'offer_type' column - before replace : \\n\", categorical_data['offer_type'].unique())\n",
    "clean_autos['offer_type'].replace({\"Angebot\":\"offer\"},inplace = True)\n",
    "print(\"\\nUnique value for 'offer_type' column - after replace :\\n\", clean_autos['offer_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no German words to translate\n",
    "categorical_data['abtest'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to return unique values without the NaN, simply chain the dropna and unique functions together\n",
    "print(\"Unique value for 'vehicle_type' column - before replace : \\n\", categorical_data['vehicle_type'].dropna().unique())\n",
    "clean_autos['vehicle_type'].replace({\"kleinwagen\":\"small car\", \"kombi\":\"combi\", \"andere\":\"other\"},inplace = True)\n",
    "print(\"\\nUnique value for 'vehicle_type' column - after replace : \\n\", clean_autos['vehicle_type'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique value for 'gearbox' column - before replace : \\n\", categorical_data['gearbox'].dropna().unique())\n",
    "clean_autos['gearbox'].replace({\"manuell\":\"manually\", \"automatik\":\"automatic\"},inplace = True)\n",
    "print(\"\\nUnique value for 'gearbox' column - after replace : \\n\", clean_autos['gearbox'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique value for 'fuel_type' column - before replace : \\n\", categorical_data['fuel_type'].dropna().unique())\n",
    "clean_autos['fuel_type'].replace({\"benzin\":\"petrol\", \"elektro\":\"electro\", \"andere\":\"other\"},inplace = True)\n",
    "print(\"\\nUnique value for 'fuel_type' column - after replace : \\n\", clean_autos['fuel_type'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique value for 'unrepaired_damage' column - before replace : \\n\", categorical_data['unrepaired_damage'].dropna().unique())\n",
    "clean_autos['unrepaired_damage'].replace({\"nein\":\"No\", \"ja\":\"Yes\"},inplace = True)\n",
    "print(\"\\nUnique value for 'unrepaired_damage' column - after replace : \\n\", clean_autos['unrepaired_damage'].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common brand/model combinations <a class=\"anchor\" id=\"s8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .size() property to get an int representing the number of elements in this object\n",
    "print(\"Top 5 Most common brand/model combinations :\\n \\n\", clean_autos.groupby(['brand', 'model']).size().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much cheaper are cars with damage than their non-damaged counterparts? <a class=\"anchor\" id=\"s9\"></a>\n",
    "\n",
    "Let's explore variations across cars with damage than their non-damaged counterparts in terms of price. In order to do so, we will aggregate over the top 5 brands using Series.index attribute to access the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select upper middle class cars\n",
    "clean_upper_middle_class=clean_autos.loc[(clean_autos['brand']== 'sonstige_autos')|(clean_autos['brand']== 'mini')|(clean_autos['brand']== 'audi')|(clean_autos['brand']== 'mercedes_benz')|(clean_autos['brand']== 'bmw')]\n",
    "\n",
    "# group by 'unrepaired_damage' & 'brand' and select 'price' column\n",
    "df_damage = clean_upper_middle_class.groupby(['unrepaired_damage', 'brand'], as_index=False).price.mean().round()\n",
    "\n",
    "# unrepaired_damage= df_damage[df_damage['unrepaired_damage']=='No'].sort_values(by = 'price', ascending=False)\n",
    "# repaired_damage= df_damage[df_damage['unrepaired_damage']=='Yes'].sort_values(by = 'price', ascending=False)\n",
    "\n",
    "unrepaired_damage= df_damage[df_damage['unrepaired_damage']=='No']\n",
    "repaired_damage= df_damage[df_damage['unrepaired_damage']=='Yes']\n",
    "display(unrepaired_damage)\n",
    "display(repaired_damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for comparison\n",
    "unrepaired_damage.reset_index(inplace=True)\n",
    "repaired_damage.reset_index(inplace=True)\n",
    "\n",
    "# Extract \"price\" column for unrepaired_damage cars \n",
    "unrepaired_price=unrepaired_damage.loc[:,'price']\n",
    "\n",
    "# Extract \"price\" column for repaired_damage cars \n",
    "repaired_price=repaired_damage.loc[:,'price']\n",
    "\n",
    "# mean difference between the 2 \"price\" columns\n",
    "price_damage_comparison=unrepaired_damage['price'] - repaired_damage['price']\n",
    "\n",
    "# mean percentage difference between the 2 \"price\" columns\n",
    "price_damage_percent_diff=((unrepaired_damage['price'] - repaired_damage['price'])/repaired_damage['price']).round()\n",
    "\n",
    "#Create a dataframe from the first series object using the dataframe constructor\n",
    "df_damage = pd.DataFrame(unrepaired_damage.loc[:,'brand'], columns=['brand'])\n",
    "df_damage['price_mean_diff'] = price_damage_comparison\n",
    "df_damage.sort_values('price_mean_diff', ascending=False)\n",
    "df_damage['price_diff (%)'] = price_damage_percent_diff\n",
    "df_damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the cars with repaired damages are more expansive that their non-repaired counterparts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![alt text](https://img.webnots.com/2016/01/arrow53.png)](#s0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
